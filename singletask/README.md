# CARP | Single-Task

## ğŸ Introduction
We evaluate our method on the `lift`, `can`, and `square` tasks from [Robomimic](https://robomimic.github.io/), as well as the Franka `kitchen` task from [Relay Policy Learning](https://arxiv.org/pdf/1910.11956), following the same experimental setup as [Diffusion Policy](https://github.com/real-stanford/diffusion_policy).

## ğŸ› ï¸ Setup

* Build [miniforge](https://github.com/conda-forge/miniforge#mambaforge) virtual environment.
```bash
curl -L -O "https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-$(uname)-$(uname -m).sh"
bash Miniforge3-$(uname)-$(uname -m).sh
```
* Build `carp-st` environment.
```bash
conda env create -f environment.yaml
```
* For `mujoco` on `Ubuntu 20.04`, we need to install the following apt packages:
```bash
sudo apt install -y libosmesa6-dev libgl1-mesa-glx libglfw3 patchelf
```

## ğŸ“Š Dataset

* Download the Robomimic datasets in both [state-based](https://diffusion-policy.cs.columbia.edu/data/training/robomimic_lowdim.zip) and [image-based](https://diffusion-policy.cs.columbia.edu/data/training/robomimic_image.zip) formats. The Kitchen dataset can be downloaded [here](https://diffusion-policy.cs.columbia.edu/data/training/kitchen.zip).
* For Robomimic, we use the `absolute-action` setting (dataset files ending with `abs.hdf5`). If you are using `relative-action` datasets instead, please refer to `singletask/env/dataset/robomimic_dataset_conversion.py` for conversion reference.

## ğŸš„ Training

### Multi-Scale Action Tokenization (MSAT)
As described in the paper, CARP consists of two stages. The first step is training a multi-scale action tokenizer to obtain representations of the action sequence at different scales.
To train the tokenizers, run:
```bash
bash ./scripts/train/train_vae.sh
```

### Coarse-to-Fine Autoregressive Prediction (CFAP)
With the action tokenizers, you can train the coarse-to-fine autoregressive model by running:
```bash
bash ./scripts/train/train_ar.sh
```

## ğŸ¤– Evaluation

* To evaluate CARP's performance, run the following command. 
```bash
bash ./scripts/eval/eval_ar.sh
```

* Additionally, we provide a basic check of action tokenization, through visulizing the differences between the reconstructed and raw actions.
```bash
bash ./scripts/eval/eval_vae.sh
```


## ğŸ“ƒ File Structure

```
carp/singletask
â”œâ”€â”€ CFAP  # Coarse-to-Fine Autoregressive model  
â”‚   â”œâ”€â”€ __init__.py  # Model initialization  
â”‚   â”œâ”€â”€ autoreg.py  # Autoregressive model  
â”‚   â””â”€â”€ basic_ar.py  # Basic implementation  
â”œâ”€â”€ env  # Robomimic and Kitchen environment dependencies  
â”œâ”€â”€ MSAT  # Multi-Scale Action Tokenizer  
â”‚   â”œâ”€â”€ __init__.py  # Model initialization  
â”‚   â”œâ”€â”€ quant.py  # Multi-scale quantization  
â”‚   â””â”€â”€ vqvae.py  # Action tokenizer  
â”œâ”€â”€ optim  # Optimization tools  
â”‚   â”œâ”€â”€ amp_opt.py  # Mixed precision optimizer  
â”‚   â””â”€â”€ lr_control.py  # Adaptive learning rate scheduler  
â”œâ”€â”€ scripts  # Bash scripts for running tasks  
â”‚   â”œâ”€â”€ eval  
â”‚   â”‚   â”œâ”€â”€ eval_ar.sh  # Evaluate CFAP  
â”‚   â”‚   â””â”€â”€ eval_vae.sh  # Evaluate MSAT  
â”‚   â””â”€â”€ train  
â”‚       â”œâ”€â”€ train_ar.sh  # Train CFAP  
â”‚       â””â”€â”€ train_vae.sh  # Train MSAT  
â”œâ”€â”€ svqvae  # Per-dimension multi-scale action tokenizer  
â”‚   â”œâ”€â”€ __init__.py  # Model initialization  
â”‚   â”œâ”€â”€ basic_vae.py  # Basic VAE architecture  
â”‚   â”œâ”€â”€ quant.py  # Multi-scale quantization  
â”‚   â””â”€â”€ vqvae.py  # Per-dimension action tokenizer  
â”œâ”€â”€ utils  # Utility functions  
â”‚   â”œâ”€â”€ arg_util.py  # Argument parsing  
â”‚   â”œâ”€â”€ data_sampler.py  # Multi-GPU data sampling  
â”‚   â”œâ”€â”€ helpers.py  # Miscellaneous helper functions  
â”‚   â”œâ”€â”€ misc.py  # Training logs  
â”‚   â””â”€â”€ train_util.py  # Training utilities  
â”œâ”€â”€ dist.py  # Distributed training  
â”œâ”€â”€ eval_ar.py  # Evaluate CFAP  
â”œâ”€â”€ eval_vae.py  # Evaluate MSAT  
â”œâ”€â”€ train_ar.py  # Train CFAP  
â”œâ”€â”€ train_vae.py  # Train per-dimension action tokenizer  
â”œâ”€â”€ trainer_ar.py  # CFAP trainer  
â””â”€â”€ trainer_vae.py  # Action tokenizer trainer  
```


## ğŸ˜µâ€ğŸ’« Troubleshooting
* If you encounter any issues during installation, feel free to open an issue or reach out for help.



